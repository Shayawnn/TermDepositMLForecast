{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Setup and Installation\n",
    "This cell handles the setup of the environment required for running the project. It installs all necessary Python packages as specified in the `requirements.txt` file. This file lists all dependencies with their respective versions, ensuring that all users have a consistent environment, which is crucial for reproducibility of results."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# !pip install numpy pandas seaborn matplotlib scikit-learn imblearn"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Library Imports and Initial Configuration\n",
    "This cell imports all necessary libraries and modules used throughout the project. Key libraries include:\n",
    "\n",
    "- `pandas` and `numpy` for data manipulation,\n",
    "- `seaborn` and `matplotlib.pyplot` for data visualization,\n",
    "- Various modules from `sklearn` for machine learning tasks like model training, feature scaling, and model evaluation,\n",
    "- `imblearn` libraries for handling imbalanced datasets using techniques like SMOTE.\n",
    "\n",
    "Additionally, this cell sets global configurations to suppress warnings and to set the plot style, which helps in maintaining a clean output and consistent visualization style across all plots."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.decomposition import PCA\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "from sklearn.feature_selection import SelectKBest, f_classif, RFECV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_curve, auc, roc_auc_score\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "from scipy.stats import chi2_contingency\n",
    "from sklearn.svm import SVC\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.style.use('fivethirtyeight')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data Management Class Definition\n",
    "This cell defines a Python class `BankData`, which is responsible for handling the dataset operations. Key functionalities include:\n",
    "\n",
    "1. **Loading Data**: The constructor (`__init__`) takes a dictionary of dataset paths and loads them into a dictionary of pandas DataFrames. This setup is beneficial for handling multiple data sources efficiently.\n",
    "2. **Basic Information Display**: The `basic_info` method provides a summary of any specified dataset, including its shape, detailed information about data types, the first few rows, and descriptive statistics. This helps in getting a quick overview and understanding the structure of the data.\n",
    "3. **Missing Value Check**: The `check_missing_values` method checks for any missing values in the dataset, essential for the preprocessing steps in data cleaning.\n",
    "4. **Data Preprocessing**: The `preprocess_data` method prepares the dataset for modeling by performing operations such as feature selection, splitting the data into training and testing sets, and encoding categorical variables.\n",
    "5. **Feature Engineering**: This method adds additional features to the dataset, such as binning numeric variables, which can help improve model performance by grouping values into bins.\n",
    "\n",
    "This class centralizes data management tasks making the code cleaner and modular, which simplifies the processes of data loading, preprocessing, and feature engineering.\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class BankData:\n",
    "    def __init__(self, dataset_paths):\n",
    "        self.df = {name: pd.read_csv(path, delimiter=';') for name, path in dataset_paths.items()}\n",
    "\n",
    "    def basic_info(self, name):\n",
    "        df = self.df[name]\n",
    "        print(f\"\\n\\n--- {name} Dataset ---\")\n",
    "        print(\"Shape:\", df.shape)\n",
    "        print(\"Info:\")\n",
    "        df.info()\n",
    "        print(\"First 5 rows:\")\n",
    "        print(df.head())\n",
    "        print(\"Summary statistics:\")\n",
    "        print(df.describe(include='all'))\n",
    "\n",
    "    def check_missing_values(self, name):\n",
    "        df = self.df[name]\n",
    "        return df.isnull().sum()\n",
    "\n",
    "    def preprocess_data(self, name):\n",
    "        df = self.df[name]\n",
    "        X = df.drop('y', axis=1)\n",
    "        y = df['y'].map({'yes': 1, 'no': 0})\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "        X_train, X_test = self.feature_engineering(X_train, X_test)\n",
    "        return X_train, X_test, y_train, y_test\n",
    "\n",
    "    def feature_engineering(self, X_train, X_test):\n",
    "        binning = KBinsDiscretizer(n_bins=5, encode='ordinal', strategy='quantile')\n",
    "        X_train['age_bin'] = binning.fit_transform(X_train[['age']])\n",
    "        X_test['age_bin'] = binning.transform(X_test[['age']])\n",
    "        return X_train, X_test\n",
    "\n",
    "    def get_data(self, name):\n",
    "        return self.df[name]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data Visualization Tools\n",
    "\n",
    "The `DataVisualizer` class provides a collection of static methods designed to facilitate the exploration and visualization of the dataset used in the TermDepositMLForecast project. Each method supports different aspects of data analysis, helping to understand distributions, correlations, and other statistical properties of the data.\n",
    "\n",
    "- **plot_target_distribution:** Visualizes the distribution of the target variable across different datasets, which is crucial for understanding class imbalances that may influence model performance.\n",
    "- **plot_histograms:** Generates histograms for numerical features to assess data distribution and identify potential outliers or skewed data.\n",
    "- **plot_correlation_matrix:** Displays a heatmap of Pearson correlation coefficients between numerical features, helping identify multicollinearity or potential predictor relationships.\n",
    "- **plot_boxplots:** Creates boxplots for each numerical feature to further investigate their distribution and spot outliers.\n",
    "- **plot_categorical_distributions:** Shows the distribution of categorical variables segmented by the target variable, providing insights into how these predictors might influence the target outcome.\n",
    "- **plot_roc_curves:** Plots Receiver Operating Characteristic (ROC) curves for models to compare their true positive rate and false positive rate, an essential metric for binary classification tasks.\n",
    "- **plot_feature_importance:** If applicable, this method visualizes the importance of each feature used by the model, aiding in understanding which features most affect the output variable.\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class DataVisualizer:\n",
    "    @staticmethod\n",
    "    def plot_target_distribution(df, target, name):\n",
    "        plt.figure(figsize=(8, 4))\n",
    "        total = float(len(df))\n",
    "        ax = sns.countplot(x=target, data=df)\n",
    "        plt.title(f\"Distribution of Target Variable in {name} Dataset\")\n",
    "        for p in ax.patches:\n",
    "            percentage = '{:.1f}%'.format(100 * p.get_height() / total)\n",
    "            x = p.get_x() + p.get_width() / 2 - 0.05\n",
    "            y = p.get_height()\n",
    "            ax.annotate(percentage, (x, y), ha='center')\n",
    "        plt.show()\n",
    "\n",
    "    @staticmethod\n",
    "    def plot_histograms(df):\n",
    "        num_features = df.select_dtypes(include=['int64', 'float64']).columns\n",
    "        df[num_features].hist(bins=15, figsize=(15, 6))\n",
    "        plt.show()\n",
    "\n",
    "    @staticmethod\n",
    "    def plot_correlation_matrix(df):\n",
    "        num_features = df.select_dtypes(include=['int64', 'float64']).columns\n",
    "        correlation_matrix = df[num_features].corr()\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        sns.heatmap(correlation_matrix, annot=True, fmt=\".2f\", cmap='coolwarm')\n",
    "        plt.title('Correlation Matrix')\n",
    "        plt.show()\n",
    "\n",
    "    @staticmethod\n",
    "    def plot_boxplots(df):\n",
    "        num_features = df.select_dtypes(include=['int64', 'float64']).columns\n",
    "        plt.figure(figsize=(15, 10))\n",
    "        for i, col in enumerate(num_features):\n",
    "            plt.subplot(4, 4, i + 1)\n",
    "            df.boxplot(column=col)\n",
    "            plt.title(col)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    @staticmethod\n",
    "    def plot_categorical_distributions(df):\n",
    "        cat_features = df.select_dtypes(include=['object']).columns.drop('y')\n",
    "        for feature in cat_features:\n",
    "            crosstab_result = pd.crosstab(df[feature], df['y'])\n",
    "            print(f\"\\n--- Crosstab of {feature} by Target 'y' ---\")\n",
    "            print(crosstab_result)\n",
    "            crosstab_result.plot(kind='bar', figsize=(10, 4), stacked=True)\n",
    "            plt.title(f'{feature} distribution by Target')\n",
    "            plt.xlabel(f'{feature}')\n",
    "            plt.ylabel('Frequency')\n",
    "            plt.show()\n",
    "\n",
    "    @staticmethod\n",
    "    def plot_roc_curves(roc_data):\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        for data in roc_data:\n",
    "            plt.plot(data['fpr'], data['tpr'], label=f\"{data['model']} (AUC = {data['auc']:.2f})\")\n",
    "        plt.plot([0, 1], [0, 1], 'k--')  # Dashed diagonal\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.title('ROC Curves')\n",
    "        plt.legend(loc='lower right')\n",
    "        plt.show()\n",
    "\n",
    "    @staticmethod\n",
    "    def plot_feature_importance(feature_importance):\n",
    "        if feature_importance is not None:\n",
    "            feature_importance.plot(kind='bar', figsize=(10, 6))\n",
    "            plt.title('Feature Importance')\n",
    "            plt.ylabel('Importance')\n",
    "            plt.xlabel('Features')\n",
    "            plt.show()\n",
    "        else:\n",
    "            print(\"Feature importance data is not available.\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Feature Selection Process\n",
    "\n",
    "In this section, we introduce the `FeatureSelector` class designed to identify the most relevant features for predicting whether a client will subscribe to a bank term deposit. The class utilizes several statistical techniques and model-based approaches to refine the feature set for the machine learning models.\n",
    "\n",
    "- **Univariate Feature Selection (`univariate_selection`):** This method applies a univariate feature selection technique using ANOVA F-test via SelectKBest to identify the top n features that have the highest statistical significance with respect to the target. The selection is performed only on numerical data.\n",
    "- **Model-based Feature Selection (`model_based_selection`):** Utilizes Recursive Feature Elimination with Cross-Validation (RFECV) using a RandomForestClassifier. This method is used after univariate feature selection to further refine the chosen features based on their importance derived from the model.\n",
    "- **Chi-squared Test for Categorical Features (`chi_squared_test`):** Performs a chi-squared test to determine the significance of categorical features with respect to the target. Features with a p-value less than 0.06 are considered significant and are added to the list of selected features.\n",
    "- **Retrieve Selected Features (`get_selected_features`):** Returns the final list of selected features that combines the results from both numerical and categorical selections.\n",
    "\n",
    "The `FeatureSelector` is instantiated and used within the data preparation phase of the pipeline in `TermDepositMLForecast` class."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class FeatureSelector:\n",
    "    def __init__(self, numerical_data, categorical_data, target):\n",
    "        self.numerical_data = numerical_data\n",
    "        self.categorical_data = categorical_data\n",
    "        self.target = target\n",
    "        self.selected_features = []\n",
    "        self.num_features = []  # To store the names of selected numerical features\n",
    "\n",
    "    def univariate_selection(self, num_features=10):\n",
    "        # Keep column names first\n",
    "        columns = self.numerical_data.columns\n",
    "        selector = SelectKBest(f_classif, k=num_features)\n",
    "        # Apply selector to numerical data\n",
    "        transformed_data = selector.fit_transform(self.numerical_data, self.target)\n",
    "        mask = selector.get_support()  # List of booleans for selected features\n",
    "        selected_columns = columns[mask]  # Filter columns by mask\n",
    "        self.num_features = selected_columns.tolist()\n",
    "        self.selected_features += self.num_features\n",
    "        # Ensure that numerical_data remains a DataFrame\n",
    "        self.numerical_data = pd.DataFrame(transformed_data, columns=self.num_features)\n",
    "        return self\n",
    "\n",
    "    def model_based_selection(self):\n",
    "        model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "        selector = RFECV(estimator=model, step=1, cv=5)\n",
    "        selected_data = self.numerical_data[self.num_features]  # Only select previously selected features\n",
    "        selector.fit(selected_data, self.target)\n",
    "        mask = selector.get_support()  # List of booleans for selected features\n",
    "        reduced_features = [feature for feature, selected in zip(self.num_features, mask) if selected]\n",
    "        self.num_features = reduced_features\n",
    "        self.selected_features = reduced_features  # Only include selected features\n",
    "        return self\n",
    "\n",
    "    def chi_squared_test(self):\n",
    "        significant_cats = []\n",
    "        for column in self.categorical_data.columns:\n",
    "            contingency_table = pd.crosstab(self.categorical_data[column], self.target)\n",
    "            chi2, p, dof, expected = chi2_contingency(contingency_table)\n",
    "            if p < 0.06:  # Using 0.06 as the significance level\n",
    "                significant_cats.append(column)\n",
    "        self.selected_features += significant_cats\n",
    "        return self\n",
    "\n",
    "    def get_selected_features(self):\n",
    "        return self.selected_features"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## TermDepositMLForecast Class\n",
    "\n",
    "This section outlines the functionality implemented in the `TermDepositMLForecast` class, which serves as the core component for preparing data, building predictive models, and evaluating their performance. This class encapsulates all functionalities required for forecasting whether a client will subscribe to a bank term deposit.\n",
    "\n",
    "### Class Initialization\n",
    "\n",
    "Upon instantiation, the `TermDepositMLForecast` class initializes its attributes including setting up the dataset path and creating instances for data visualization.\n",
    "\n",
    "- `bank_data` loads the dataset specified by the path provided during initialization.\n",
    "- `data_visualizer` is an instance of the `DataVisualizer` class, which will be used for visualizing data distributions and results.\n",
    "\n",
    "### Data Preparation\n",
    "\n",
    "The `prepare_data` method is responsible for the following:\n",
    "- Loading and preprocessing the data using `BankData` class methods.\n",
    "- Identifying numerical and categorical columns from the dataset.\n",
    "- Feature selection is performed by an instance of the `FeatureSelector` class. It applies univariate selection, model-based selection using Random Forest, and a Chi-squared test for categorical variables to identify the most predictive features.\n",
    "- The method updates the training (`X_train`) and testing (`X_test`) datasets to include only the selected features.\n",
    "\n",
    "### Pipeline Construction\n",
    "\n",
    "The `build_pipeline` method constructs a machine learning pipeline that includes:\n",
    "- Data preprocessing using column transformers:\n",
    "  - Numerical data is scaled.\n",
    "  - Categorical data is encoded using one-hot encoding.\n",
    "- Application of PCA (Principal Component Analysis) is optional and can be configured via the `use_pca` flag.\n",
    "- SMOTE (Synthetic Minority Over-sampling Technique) is integrated to address class imbalance.\n",
    "- A specified classifier is added to the pipeline.\n",
    "\n",
    "#### Numerical Transformations\n",
    "\n",
    "- **Imputation**: Missing values in numerical features are imputed using the median of each column, which is robust to outliers compared to the mean.\n",
    "- **Scaling**: Data is standardized by removing the mean and scaling to unit variance. This step ensures that the magnitude of the numerical values does not bias the model, which is particularly important for models that rely on the distance between data points, like SVM.\n",
    "\n",
    "#### Categorical Transformations\n",
    "\n",
    "- **Imputation**: Missing values in categorical features are replaced with the string 'missing'. This approach treats missing data as a separate category, avoiding the introduction of bias that might occur if imputed with the most frequent category.\n",
    "- **One-Hot Encoding**: Converts categorical variables into a form that could be provided to ML algorithms to do a better job in prediction. It creates binary columns for each category and assigns a value of 1 or 0. This encoding is essential for handling non-ordinal categorical variables in machine learning.\n",
    "\n",
    "#### Principal Component Analysis (PCA)\n",
    "\n",
    "- **PCA Application**: When the `use_pca` flag is set to True, PCA is applied to reduce the dimensionality of the data. It transforms the data into a new coordinate system, reducing the number of features while retaining the variance in the data as much as possible. This step can help in alleviating issues from the curse of dimensionality, especially in datasets with many features.\n",
    "\n",
    "#### Synthetic Minority Over-sampling Technique (SMOTE)\n",
    "\n",
    "- **Handling Class Imbalance**: SMOTE is used to oversample the minority class by creating synthetic samples. This approach helps to balance the dataset, improving the performance of the classifier on imbalanced data by addressing the issue where minority class observations are often overlooked or misclassified.\n",
    "\n",
    "#### ImbPipeline\n",
    "\n",
    "- **Enhanced Pipeline for Imbalanced Data**: Uses an `Imbalanced Pipeline` from the `imbalanced-learn` library, specifically designed to integrate resampling techniques seamlessly within the cross-validation process.\n",
    "\n",
    "### Model Training and Hyperparameter Tuning\n",
    "\n",
    "The `train_models` method:\n",
    "- Initializes classifiers with their respective hyperparameters.\n",
    "- For each classifier, a pipeline is built, optionally tuned using grid search or random search, and trained on the dataset.\n",
    "- Model performance is evaluated using accuracy, precision, recall, F1 score, and ROC AUC metrics on both training and testing sets.\n",
    "- The method returns the evaluation results and ROC curve data for further analysis and visualization.\n",
    "\n",
    "### Classifiers and Their Attributes\n",
    "\n",
    "- **Logistic Regression**: Utilized with attributes like `max_iter` for convergence and `solver` for optimization. Specific hyperparameters like `C` (regularization strength) and `penalty` (type of regularization) are tuned to optimize model performance.\n",
    "- **Random Forest**: An ensemble method that uses a combination of decision trees. It is configured with hyperparameters such as `n_estimators` (number of trees), `max_depth` (depth of each tree), `min_samples_split`, and `min_samples_leaf` to control the fitting process.\n",
    "- **Support Vector Machine (SVM)**: Applied with a linear kernel to balance complexity and performance. Hyperparameters like `C` (penalty parameter) and `gamma` (kernel coefficient) are essential for the model's sensitivity to the training data distribution.\n",
    "\n",
    "### Model Evaluation\n",
    "\n",
    "The `evaluate_model` method computes various performance metrics for the provided model and datasets to quantify its effectiveness in predicting whether clients will subscribe to a term deposit.\n",
    "\n",
    "- **Accuracy**: Measures the overall correctness of the model, defined as the ratio of true predictions (both true positives and true negatives) to the total number of cases.\n",
    "- **Precision**: Indicates the accuracy of positive predictions, formulated as the ratio of true positives to all predicted positives. High precision relates to a low rate of false positives.\n",
    "- **Recall**: Measures the model's ability to detect positive instances, calculated as the ratio of true positives to all actual positives. High recall relates to a low rate of false negatives.\n",
    "- **F1 Score**: Combines precision and recall into a single metric by taking their harmonic mean. It balances both metrics, especially useful when dealing with imbalanced datasets.\n",
    "- **ROC AUC**: The area under the receiver operating characteristic curve. It evaluates the trade-off between the true positive rate and false positive rate, providing a single measure of general model performance across all classification thresholds.\n",
    "\n",
    "### Feature Importance\n",
    "\n",
    "The `get_feature_importance` method extracts feature importances from trained models, aiding in the interpretation of the models by highlighting which features most influence predictions.\n",
    "\n",
    "### Hyperparameter Tuning Functions\n",
    "\n",
    "- `perform_grid_search` and `perform_random_search` are implemented to fine-tune model parameters, aiming to improve model performance by searching over a specified parameter space and using cross-validation.\n",
    "\n",
    "#### Grid Search and Random Search\n",
    "\n",
    "- **Grid Search**: Conducts an exhaustive search over a specified parameter grid. This method trains and evaluates a model for each combination of algorithm parameters specified in a grid, facilitating the identification of the most optimal parameters.\n",
    "- **Random Search**: Samples algorithm parameters from a grid of possible values. It offers a budget-friendly alternative to grid search by limiting the number of parameter combinations that are evaluated.\n",
    "\n",
    "This structured approach ensures a robust framework for training and evaluating machine learning models, making it easier to compare different algorithms and their configurations.\n",
    "\n",
    "### Getter Methods\n",
    "\n",
    "- **`get_bank_data`**: Returns the `BankData` instance associated with the class. This instance contains the data and preprocessing methods necessary for the machine learning tasks.\n",
    "\n",
    "- **`get_model`**: Fetches a specific trained model by name. This is useful when multiple models are trained and stored within the class.\n",
    "\n",
    "- **`get_model_results`**: Retrieves the results of all models trained in the class. These results typically include metrics such as accuracy, precision, recall, F1 score, and ROC AUC for each model.\n",
    "\n",
    "- **`get_roc_data`**: Provides the ROC curve data for each model. This data is essential for evaluating the trade-offs between the true positive rate and false positive rate at various threshold settings.\n",
    "\n",
    "- **`get_selected_features`**: Returns the list of feature names that were selected as the most informative for predicting the outcome. This selection is based on the feature selection process applied during data preparation.\n",
    "\n",
    "These methods provide a safe way to access the internal state of an instance of `TermDepositMLForecast` without directly exposing the class's fields to external modification."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class TermDepositMLForecast:\n",
    "    def __init__(self):\n",
    "        self.roc_data = []\n",
    "        self.model_results = []\n",
    "        self.selected_features = None\n",
    "        self.bank_data = BankData({\n",
    "                'Bank Additional Full': './datasets/bank-additional-full.csv',\n",
    "                # 'Bank Additional': './datasets/bank-additional.csv',\n",
    "                # 'Bank Full Old': './datasets/bank-full.csv',\n",
    "                # 'Bank Old': './datasets/bank.csv'\n",
    "            }\n",
    "        )\n",
    "        self.data_visualizer = DataVisualizer()\n",
    "        self.X_train = None\n",
    "        self.X_test = None\n",
    "        self.y_train = None\n",
    "        self.y_test = None\n",
    "        self.models = {}\n",
    "\n",
    "    def prepare_data(self):\n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = self.bank_data.preprocess_data('Bank Additional Full')\n",
    "        num_cols = [cname for cname in self.X_train.columns if self.X_train[cname].dtype in ['int64', 'float64']]\n",
    "        cat_cols = [cname for cname in self.X_train.columns if self.X_train[cname].dtype == 'object']\n",
    "\n",
    "        # Applying feature selection\n",
    "        fs = FeatureSelector(self.X_train[num_cols], self.X_train[cat_cols], self.y_train)\n",
    "        fs.univariate_selection().model_based_selection().chi_squared_test()\n",
    "        self.selected_features = fs.get_selected_features()\n",
    "\n",
    "        # Update X_train and X_test based on selected features\n",
    "        self.X_train = self.X_train[self.selected_features]\n",
    "        self.X_test = self.X_test[self.selected_features]\n",
    "\n",
    "    def build_pipeline(self, classifier, use_pca=False):\n",
    "        numerical_cols = [cname for cname in self.X_train.columns if self.X_train[cname].dtype in ['int64', 'float64']]\n",
    "        categorical_cols = [cname for cname in self.X_train.columns if self.X_train[cname].dtype == \"object\"]\n",
    "\n",
    "        numerical_transformer = Pipeline(steps=[\n",
    "            ('imputer', SimpleImputer(strategy='median')),     # Impute missing values\n",
    "            ('scaler', StandardScaler()),                      # Standardize features\n",
    "        ])\n",
    "\n",
    "        categorical_transformer = Pipeline(steps=[\n",
    "            ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "            ('onehot', OneHotEncoder(handle_unknown='ignore'))      # Apply one-hot encoding\n",
    "        ])\n",
    "\n",
    "        # Choose whether to use PCA\n",
    "        if use_pca:\n",
    "            pca_transformer = Pipeline(steps=[\n",
    "                ('scaler', StandardScaler()),  # Scaling is done before PCA\n",
    "                ('pca', PCA(n_components=0.95))\n",
    "            ])\n",
    "            preprocessor = ColumnTransformer(\n",
    "                transformers=[\n",
    "                    ('num', pca_transformer, numerical_cols),\n",
    "                    ('cat', categorical_transformer, categorical_cols)\n",
    "                ])\n",
    "        else:\n",
    "            preprocessor = ColumnTransformer(\n",
    "                transformers=[\n",
    "                    ('num', numerical_transformer, numerical_cols),\n",
    "                    ('cat', categorical_transformer, categorical_cols)\n",
    "                ])\n",
    "\n",
    "        # Final pipeline including SMOTE and classifier\n",
    "        pipeline = ImbPipeline(steps=[\n",
    "            ('preprocessor', preprocessor),\n",
    "            ('smote', SMOTE(random_state=42)),  # Handle class imbalance\n",
    "            ('classifier', classifier)  # Classifier\n",
    "        ])\n",
    "        return pipeline\n",
    "\n",
    "    def train_models(self, use_pca=False, tune=False, tune_search_method='grid'):\n",
    "        # Initializing the models\n",
    "        # Define the classifiers to be used\n",
    "        classifiers = {\n",
    "            'Logistic Regression': (LogisticRegression(max_iter=1000, solver='liblinear'), log_reg_params),\n",
    "            'Random Forest': (RandomForestClassifier(n_estimators=100, random_state=42), rf_params),\n",
    "            'SVM': (SVC(kernel='linear', random_state=42, probability=True), svm_params)  # Linear kernel is chosen for simplicity and performance\n",
    "        }\n",
    "\n",
    "        results = []\n",
    "        roc_data = []\n",
    "\n",
    "        # Loop through the classifiers to create, train, and evaluate each one\n",
    "        for name, (classifier, params) in tqdm(classifiers.items(), desc=\"Training Models\"):\n",
    "            try:\n",
    "                pipeline = self.build_pipeline(classifier, use_pca=use_pca)\n",
    "\n",
    "                if tune:\n",
    "                    print(f\"Performing {tune_search_method} hyperparameter tuning for {name}\")\n",
    "                    if tune_search_method == 'grid':\n",
    "                        tuned_pipeline = self.perform_grid_search(pipeline, params, self.X_train, self.y_train)\n",
    "                    elif tune_search_method == 'random':\n",
    "                        tuned_pipeline = self.perform_random_search(pipeline, params, self.X_train, self.y_train)\n",
    "                    elif tune_search_method == 'both':\n",
    "                        # Perform both searches, compare and choose the best\n",
    "                        grid_pipeline = self.perform_grid_search(pipeline, params, self.X_train, self.y_train)\n",
    "                        random_pipeline = self.perform_random_search(pipeline, params, self.X_train, self.y_train)\n",
    "                        # Choosing the model with the best cross-validation ROC AUC score\n",
    "                        tuned_pipeline = grid_pipeline if grid_pipeline.best_score_ >= random_pipeline.best_score_ else random_pipeline\n",
    "\n",
    "                    pipeline = tuned_pipeline  # Use the tuned pipeline\n",
    "                    print(f\"Training {name} with best parameters.\")\n",
    "\n",
    "                # Fit the model pipeline on the training data\n",
    "                pipeline.fit(self.X_train, self.y_train)\n",
    "\n",
    "                self.models[name] = pipeline  # Store the trained pipeline\n",
    "\n",
    "                # Evaluate the model\n",
    "                train_metrics, test_metrics, fpr, tpr, thresholds = self.evaluate_model(pipeline, self.X_train, self.y_train, self.X_test, self.y_test)\n",
    "\n",
    "                # Collect results\n",
    "                results.append({\n",
    "                    'Model': name,\n",
    "                    'Train Accuracy': train_metrics['Accuracy'],\n",
    "                    'Test Accuracy': test_metrics['Accuracy'],\n",
    "                    'Train Precision': train_metrics['Precision'],\n",
    "                    'Test Precision': test_metrics['Precision'],\n",
    "                    'Train Recall': train_metrics['Recall'],\n",
    "                    'Test Recall': test_metrics['Recall'],\n",
    "                    'Train F1': train_metrics['F1 Score'],\n",
    "                    'Test F1': test_metrics['F1 Score'],\n",
    "                    'Test ROC AUC': test_metrics['ROC AUC']\n",
    "                })\n",
    "                roc_data.append({'model': name, 'fpr': fpr, 'tpr': tpr, 'auc': test_metrics['ROC AUC']})\n",
    "            except Exception as e:\n",
    "                print(f\"Error training {name}: {e}\")\n",
    "\n",
    "        # Create DataFrame for results\n",
    "        self.model_results = pd.DataFrame(results)\n",
    "        self.roc_data = roc_data\n",
    "        return self.model_results, self.roc_data\n",
    "\n",
    "    def evaluate_model(self, model, X_train, y_train, X_test, y_test):\n",
    "        # Predictions on training and test set\n",
    "        y_pred_train = model.predict(X_train)\n",
    "        y_pred_test = model.predict(X_test)\n",
    "        y_prob_test = model.predict_proba(X_test)[:, 1]  # Get probabilities for the positive class\n",
    "\n",
    "        # Compute metrics for training and testing sets\n",
    "        metrics_train = {\n",
    "            'Accuracy': accuracy_score(y_train, y_pred_train),\n",
    "            'Precision': precision_score(y_train, y_pred_train),\n",
    "            'Recall': recall_score(y_train, y_pred_train),\n",
    "            'F1 Score': f1_score(y_train, y_pred_train),\n",
    "            'ROC AUC': roc_auc_score(y_train, model.predict_proba(X_train)[:, 1])  # ROC AUC for training\n",
    "        }\n",
    "\n",
    "        metrics_test = {\n",
    "            'Accuracy': accuracy_score(y_test, y_pred_test),\n",
    "            'Precision': precision_score(y_test, y_pred_test),\n",
    "            'Recall': recall_score(y_test, y_pred_test),\n",
    "            'F1 Score': f1_score(y_test, y_pred_test),\n",
    "            'ROC AUC': roc_auc_score(y_test, y_prob_test)  # ROC AUC for testing\n",
    "        }\n",
    "\n",
    "        fpr, tpr, thresholds = roc_curve(y_test, y_prob_test)\n",
    "        return metrics_train, metrics_test, fpr, tpr, thresholds\n",
    "\n",
    "    def perform_grid_search(self, pipeline, param_grid, X_train, y_train, cv=5):\n",
    "        \"\"\"\n",
    "        Perform grid search hyperparameter tuning.\n",
    "        \"\"\"\n",
    "        grid_search = GridSearchCV(estimator=pipeline, param_grid=param_grid, cv=cv, scoring='roc_auc', verbose=2, n_jobs=-1)\n",
    "        with tqdm(total=len(param_grid[next(iter(param_grid))]) * cv) as pbar:\n",
    "            grid_search.fit(X_train, y_train)\n",
    "            pbar.update(1)\n",
    "        print(\"Best parameters:\", grid_search.best_params_)\n",
    "        print(\"Best cross-validation ROC AUC score: {:.3f}\".format(grid_search.best_score_))\n",
    "        return grid_search.best_estimator_\n",
    "\n",
    "    def perform_random_search(self, pipeline, param_distributions, X_train, y_train, n_iter=100, cv=5):\n",
    "        \"\"\"\n",
    "        Perform random search hyperparameter tuning.\n",
    "        \"\"\"\n",
    "        random_search = RandomizedSearchCV(estimator=pipeline, param_distributions=param_distributions, n_iter=n_iter, cv=cv, scoring='roc_auc', verbose=2, random_state=42, n_jobs=-1)\n",
    "        with tqdm(total=n_iter * cv) as pbar:\n",
    "            random_search.fit(X_train, y_train)\n",
    "            pbar.update(1)\n",
    "        print(\"Best parameters:\", random_search.best_params_)\n",
    "        print(\"Best cross-validation ROC AUC score: {:.3f}\".format(random_search.best_score_))\n",
    "        return random_search.best_estimator_\n",
    "\n",
    "    def get_feature_importance(self, model, feature_names):\n",
    "        if hasattr(model, 'feature_importances_'):\n",
    "            # Handle tree-based models\n",
    "            importances = model.feature_importances_\n",
    "        elif hasattr(model, 'coef_'):\n",
    "            # Handle models with coefficients (like Logistic Regression)\n",
    "            importances = np.abs(model.coef_[0])\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "        feature_importance = pd.DataFrame(importances, index=feature_names, columns=['importance'])\n",
    "        feature_importance = feature_importance.sort_values(by='importance', ascending=False)\n",
    "        return feature_importance\n",
    "\n",
    "    # Getters\n",
    "    def get_bank_data(self):\n",
    "        return self.bank_data\n",
    "\n",
    "    def get_model(self, model_name):\n",
    "        return self.models.get(model_name, None)\n",
    "\n",
    "    def get_model_results(self):\n",
    "        return self.model_results\n",
    "\n",
    "    def get_roc_data(self):\n",
    "        return self.roc_data\n",
    "\n",
    "    def get_selected_features(self):\n",
    "        return self.selected_features"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Hyperparameter Grids\n",
    "\n",
    "This section outlines the definition of hyperparameter grids for the logistic regression, random forest, and SVM classifiers used in the `TermDepositMLForecast` project. These grids are used during the hyperparameter tuning process to find the optimal settings for each model.\n",
    "\n",
    "### Logistic Regression Parameters\n",
    "\n",
    "- **`classifier__C`**: The regularization strength, which inversely controls the amount of overfitting. Lower values increase regularization, which can help to reduce overfitting but may lead to underfitting if set too high. The values tested are `[0.01, 0.1, 1, 10, 100]`.\n",
    "- **`classifier__penalty`**: Specifies the norm used in the penalization (regularization term). The options are `['l1', 'l2']`:\n",
    "  - **`l1`**: Lasso regularization which adds a penalty equal to the absolute value of the magnitude of coefficients. This can lead to sparse models (with few coefficients set to zero).\n",
    "  - **`l2`**: Ridge regularization which adds a penalty equal to the square of the magnitude of coefficients. This tends to distribute error among all the terms but doesn't set coefficients to zero.\n",
    "\n",
    "### Random Forest Parameters\n",
    "\n",
    "- **`classifier__n_estimators`**: The number of trees in the forest. Increasing the number of trees generally improves the performance but also increases the computational load. Values tested include `[50, 100, 200]`.\n",
    "- **`classifier__max_depth`**: The maximum depth of each tree. Allowed values are `[None, 10, 20, 30]`, where `None` means no limit, potentially leading to fully grown and very deep trees which might overfit the data.\n",
    "- **`classifier__min_samples_split`**: The minimum number of samples required to split an internal node. Higher values prevent the model from learning overly specific patterns, thus lowering overfitting. Tested values are `[2, 5, 10]`.\n",
    "- **`classifier__min_samples_leaf`**: The minimum number of samples required to be at a leaf node. Like `min_samples_split`, this parameter affects the depth of the tree. The values being tested are `[1, 2, 4]`.\n",
    "\n",
    "### SVM Parameters\n",
    "\n",
    "- **`classifier__C`**: Penalty parameter C of the error term. It controls the trade off between smooth decision boundary and classifying the training points correctly. SVM performance is highly sensitive to this parameter. Values considered are `[0.1, 1, 10]`.\n",
    "- **`classifier__gamma`**: Kernel coefficient for `rbf`, `poly` and `sigmoid`. Here, since we use a linear kernel, this parameter will be explored within the options `['scale', 'auto']`, which automates the selection of gamma based on the number of features (scale) or uses 1/n_features (auto).\n",
    "\n",
    "### Purpose of Hyperparameter Tuning\n",
    "\n",
    "Hyperparameter tuning is critical in optimizing the model's performance, balancing the bias-variance tradeoff, and ensuring that the model generalizes well to new, unseen data. Using GridSearchCV or RandomizedSearchCV in the training process helps in systematically working through multiple combinations of parameter values, directing the search into the region of the best performance of the model.\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Parameter grid for Logistic Regression\n",
    "log_reg_params = {\n",
    "    'classifier__C': [0.01, 0.1, 1, 10, 100],\n",
    "    'classifier__penalty': ['l1', 'l2']\n",
    "}\n",
    "\n",
    "# Parameter grid for Random Forest\n",
    "rf_params = {\n",
    "    'classifier__n_estimators': [50, 100, 200],\n",
    "    'classifier__max_depth': [None, 10, 20, 30],\n",
    "    'classifier__min_samples_split': [2, 5, 10],\n",
    "    'classifier__min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# Parameter grid for SVM\n",
    "svm_params = {\n",
    "    'classifier__C': [0.1, 1, 10],\n",
    "    'classifier__gamma': ['scale', 'auto']\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Instantiating the class\n",
    "TDMLForecast = TermDepositMLForecast()\n",
    "\n",
    "# Bank Data\n",
    "bank_data = TDMLForecast.get_bank_data()\n",
    "\n",
    "# Visualizations\n",
    "visualizer = TDMLForecast.data_visualizer"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Main Execution\n",
    "forecast = TermDepositMLForecast()\n",
    "forecast.prepare_data()  # Ensures data is loaded, split, and basic feature engineering is applied"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "results, roc_data = forecast.train_models(use_pca=False, tune=True, tune_search_method='both')  # Train and compare different models"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Basic Information\n",
    "bank_data.basic_info('Bank Additional Full')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Visualizing target distribution\n",
    "visualizer.plot_target_distribution(bank_data, 'y', 'Bank Additional Full')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Visualizing histograms for numerical features\n",
    "visualizer.plot_histograms(bank_data)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Visualizing boxplots for numerical features categorized by the target variable\n",
    "visualizer.plot_boxplots(bank_data)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Visualizing distributions for categorical features\n",
    "visualizer.plot_categorical_distributions(bank_data)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Visualizing the correlation matrix\n",
    "visualizer.plot_correlation_matrix(bank_data)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Get selected features\n",
    "print(f\"Selected Features:\\n{forecast.get_selected_features()}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Get a specific model, e.g., Random Forest\n",
    "model_name = forecast.get_model('Random Forest')\n",
    "trained_pipeline = model_name.named_steps['classifier']\n",
    "# trained_pipeline = forecast.models[model_name].named_steps['classifier']\n",
    "feature_names = forecast.X_train.columns"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Get and plot feature importance\n",
    "feature_importance = forecast.get_feature_importance(trained_pipeline, feature_names)\n",
    "print(f\"Feature Importance:/n{feature_importance}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "visualizer.plot_feature_importance(feature_importance)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(f\"Model Results:\\n{forecast.get_model_results()}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "visualizer.plot_roc_curves(roc_data)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}